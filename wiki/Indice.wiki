= Introduction =

Migración de las implementaciones realizadas en YALE 3.4 a RapidMiner 4.1
La idea es utilizar todo lo que RapidMiner 4.1 incluye y reducir la programación propia al mínimo.

= Problema actual =
----

¿Y si pudiera usar el !AttributeSubsetPreprocessing para hacer las discretizaciones?
Si hay varias series sólo tengo que hacer una entrada por cada grupo de atributos y ya está.
ESTUDIAR:

¿como hacer que el BinDiscretization (por ejemplo) actúe sobre todos? Realmente hay que crear un idéntico pero modificado, ¿que ventaja tiene entonces utilizar el AttributeSubsetPreprocessing? Pero lo que es peor,si tengo que tratar varias veces un conjunto de ejemplos entonces me va a quedar un conjunto de modelos uno para cada serie. Supongo que eso no es problema pero puede ser inconveniente en la selección de los modelos.

LECCIONES:
Se comprueba que los atributos son realmente sustituidos. El orden en que quedan es: 
  * Si solo se procesan algunos, entonces quedan los atributos especiales, los modificados y el resto.
  * en caso de que la expresión regular afecte a todos, entonces quedan los modificados y los especiales.

-----
ESTUDIAR:  El !SimilarityUtil es capaz de usar una similitud que le venga en la lista de objetos. ¿se podría crear una similitud que tenga en cuenta la discretización? Si es así ¿habría que modificar el knnlearner?

LECCIONES:
  # Se puede crear un operador que se encargue de crear una similitud en la que almacene el modelo de discretización.
  # Aunque en la lista del inputContainer (que es donde están los objetos que entran a un operador) sólo tenga un modelo éste vendrá  dentro de un ~~!ModelContainer~~ !GroupedModel. El apply() de un ~~!ModelContainer~~ !GroupedModel realiza la aplicación secuencial de todos los modelos que incluya.
La cuestión es ver como afecta cuando además del modelo de discretización exista uno de aprendizaje en el ~~!ModelContainer~~ !GroupedModel.
  # Hay que crear una clase base de la que dependan todas las similitudes por lo que se pueda requerir; en el caso del kernel hay que almacenar los límites del modelo de discretización. La clase debe definirse al nivel de AbstractRealValueBasedSimilarity para evitar la comprobación que se hace en el init de AbstractRealValueBasedSimilarity de que todos los atributos sean numéricos. En nuestro caso tienen que ser nominales.


----

= Detalles =
AmpliaciOn a series

La idea de ampliar la discretización a series se enfoca por medio de hacer nuevos operadores de discretización olvidando la extensión de RM con las listas de bloques.
Estos operadores se limitan (caso unidimensional) a generar el mismo rango para todos los atributos.
Una vez implementados se puede ver la posibilidad de incluir el código en el operador original.


==Estructura del plugin==
=== qbts.distances ===
  * Se definen aquí todas las distancias, que heredan de !AbstractExtendedRealValueBasedSimilarity y el operador que genera la similitud denominado QBSimilaritySetup

=== qbts.preprocessing.discretization ===
  * Contiene los discretizadores de RM ampliados a la aplicación de series.
  * También existe un !DiscretizationModelSeries que es una herencia directa y casi vacía del !DiscretizationModel de RM que se crea sólo por que los constructores de !DiscretizationModel son privados y por tanto debe estar en el mismo paquete en que sea accedido.

~~qbts.discretization~~

 * ~~yale.operator.learner.lazy Incluye código copiado de RM y ligeramente modificado. Incluye un nuevo KNNLearner y !SimiliarityUtil, ver [KNNLearnerSimilarity razonamiento]~~

[Comentarios] 

= IDEAS =
  * ¿Y si la modificación del KNNLearner y el !SimiliarityUtil se hace para añadir una !UserBasedSimilarity ? No hace falta porque el KNNLearner puede usar la similitud que venga en la lista de objetos de entrada
  * El KnnLearner incluido en RM4.1 permite la aplicación de una similitud que esté en la cadena de objetos de entrada.

  * Se crea un operador cuya salida sea una similitud.
  * Se crea una clase abstracta de la que deriven todas las similitudes
{{{
package qbts.distances;

import com.rapidminer.example.ExampleSet;
import com.rapidminer.example.Tools;
import com.rapidminer.operator.OperatorException;
import com.rapidminer.operator.preprocessing.PreprocessingModel;
import com.rapidminer.operator.similarity.attributebased.AbstractValueBasedSimilarity;

public abstract class AbstractExtendedRealValueBasedSimilarity extends
		AbstractValueBasedSimilarity{

	private PreprocessingModel model;
//// SI NO HACE NADA SE ¿PUEDE QUITAR EL METODO COMPLETO? SE SUPONE QUE SE LLAMARA AL PADRE.
	public void init(ExampleSet exampleSet) throws OperatorException {
             // Tools.onlyNumericalAttributes(exampleSet, "value based similarities");
		super.init(exampleSet);
	}
}
}}}
  * Se crea una Clase para cada similitud. Cada clase tendrá que comprobar los atributos que quiere con una llamada a Tools.only....
{{{
	public void init(ExampleSet es) throws OperatorException {
		Tools.onlyNominalAttributes(es, "QSI similarity");
		super.init(es);
	}

}}}

--------

= [FAQ] =