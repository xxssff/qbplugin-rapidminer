= Introduction =

Migraci칩n de las implementaciones realizadas en YALE 3.4 a RapidMiner 4.1
La idea es utilizar todo lo que RapidMiner 4.1 incluye y reducir la programaci칩n propia al m칤nimo.

= Problema actual =
----
ESTUDIAR:  El !SimilarityUtil es capaz de usar una similitud que le venga en la lista de objetos. 쯥e podr칤a crear una similitud que tenga en cuenta la discretizaci칩n? Si es as칤 쯛abr칤a que modificar el knnlearner?

LECCIONES:
  # Se puede crear un operador que se encargue de crear una similitud en la que almacene el modelo de discretizaci칩n.
  # Aunque en la lista del inputContainer (que es donde est치n los objetos que entran a un operador) s칩lo tenga un modelo 칠ste vendr치  dentro de un !ModelContainer. El apply() de un modelContainer realiza la aplicaci칩n secuencial de todos los modelos que incluya.
La cuesti칩n es ver como afecta cuando adem치s del modelo de discretizaci칩n exista uno de aprendizaje en el !ModelContainer.
  # Hay que crear una clase base de la que dependan todas las similitudes por lo que se pueda requerir; en el caso del kernel hay que almacenar los l칤mites del modelo de discretizaci칩n. La clase debe definirse al nivel de AbstractRealValueBasedSimilarity para evitar la comprobaci칩n que se hace en el init de AbstractRealValueBasedSimilarity de que todos los atributos sean num칠ricos. En nuestro caso tienen que ser nominales.


----

= Detalles =
AmpliaciOn a series

La idea de ampliar la discretizaci蚤 a series se enfoca por medio de hacer nuevos operadores de discretizaci蚤 olvidando la extensi蚤 de RM con las listas de bloques.
Estos operadores se limitan (caso unidimensional) a generar el mismo rango para todos los atributos.
Una vez implementados se puede ver la posibilidad de incluir el c祚igo en el operador original.

Estructura del plugin

El KnnLearner incluido en RM4.1 permite la aplicaci칩n de una similitud que est칠 en la cadena de objetos de entrada.

  * Se crea un operador cuya salida sea una similitud.
  * Se crea una clase abstracta de la que deriven todas las similitudes
{{{
package qbts.distances;

import com.rapidminer.example.ExampleSet;
import com.rapidminer.example.Tools;
import com.rapidminer.operator.OperatorException;
import com.rapidminer.operator.preprocessing.PreprocessingModel;
import com.rapidminer.operator.similarity.attributebased.AbstractValueBasedSimilarity;

public abstract class AbstractExtendedRealValueBasedSimilarity extends
		AbstractValueBasedSimilarity{

	private PreprocessingModel model;
//// SI NO HACE NADA SE 쯇UEDE QUITAR EL METODO COMPLETO? SE SUPONE QUE SE LLAMARA AL PADRE.
	public void init(ExampleSet exampleSet) throws OperatorException {
             // Tools.onlyNumericalAttributes(exampleSet, "value based similarities");
		super.init(exampleSet);
	}
}
}}}
  * Se crea una Clase para cada similitud. Cada clase tendr치 que comprobar los atributos que quiere con una llamada a Tools.only....
{{{
	public void init(ExampleSet es) throws OperatorException {
		Tools.onlyNominalAttributes(es, "QSI similarity");
		super.init(es);
	}

}}}

~~qbts.discretization~~

 * ~~yale.operator.learner.lazy Incluye c칩digo copiado de RM y ligeramente modificado. Incluye un nuevo KNNLearner y !SimiliarityUtil, ver [KNNLearnerSimilarity razonamiento]~~

[Comentarios] 

= IDEAS =
쯏 si la modificaci칩n del KNNLearner y el !SimiliarityUtil se hace para a침adir una !UserBasedSimilarity ? As칤 en lugar de hacer una modificaci칩n por similitud se hace una y se crean similitudes que se puedan referenciar para su instanciaci칩n. La idea ser칤a a침adir un nuevo par치metro en el KNNLearner para poder indicar el camino de la clase a usar. Esto se usa en alg칰n otro operador.... Seguramente habr칤a que a침adir una nueva entradas en el !Mapper para colocar la opci칩n de !UserBasedSimilarity. En ese caso se podr칤a ampliar siguiendo el mecanismo usado en 
{{{
UserBasedPerformance

package com.rapidminer.operator.performance;
...
try {
criterionClass = com.rapidminer.tools.Tools.classForName(className);
if (PerformanceCriterion.class.isAssignableFrom(criterionClass)) {
	PerformanceCriterion c = null;
	if ((parameter != null) && (parameter.trim().length() > 0)) {
		java.lang.reflect.Constructor constructor = criterionClass.getConstructor(new Class[] { String.class });
		c = (PerformanceCriterion) constructor.newInstance(new Object[] { parameter });
	} else {
		c = (PerformanceCriterion) criterionClass.newInstance();
	}
	if (!(c instanceof MeasuredPerformance)) {
		logError("Only subclasses of MeasuredPerformance are supported as user based criteria. Skipping '"+className+"'...");
	} else {
		performanceCriteria.add(c);
		if (userCriteria != null)
			userCriteria.add(c);
	}
} else {
	logError("Only subclasses of MeasuredPerformance are supported as user based criteria. Skipping '"+className+"'...");
}


}}}

--------

= [FAQ] =